{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04bc17ad",
   "metadata": {},
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e9b778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389f4ff3",
   "metadata": {},
   "source": [
    "The cell below loads the model which contains the word embeddings. You will need to install this on your system _seperately_ to Spacy. This is done with:\n",
    "\n",
    "```bash\n",
    "python -m spacy download en_core_web_lg\n",
    "```\n",
    "\n",
    "You can choose `en_core_web_sm`, `_md` or `_lg` (small, medium, large)- but the larger the more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7025b0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (uncomment the last line and run once)\n",
    "# let's download a preetrained word2vec model - this may take a while\n",
    "# !python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62657493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the downloaded model\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09c3956",
   "metadata": {},
   "source": [
    "The `en_core_web_lg` will give us an embedding vector of length 300. It is also the number of parameters in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab9258d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the vector of the word \"hello\" and print its shape\n",
    "nlp('hello').vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12071545",
   "metadata": {},
   "source": [
    "The following cell measures the similarity of three words, with themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00c10ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nlp('cat lion pet')\n",
    "for t1 in tokens:\n",
    "    for t2 in tokens:\n",
    "        print(t1.text, t2.text, t1.similarity(t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf30095a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "###  <span style=\"color:red\"> Exercise 1 </span>\n",
    "Repeat the above with 3 words of your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1523d05c",
   "metadata": {},
   "source": [
    "Below is a pretty classic exercise to do. We are going to take 3 words and try to find words that relate to a relationship of these words. For example what words relate to food and fruit but not burgers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0d90ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words to Vectors\n",
    "food = nlp('food')\n",
    "fruit = nlp('fruit')\n",
    "burger = nlp('burger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c056a2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How similar are these words?\n",
    "food_fruit = food.similarity(fruit)\n",
    "fruit_burger = fruit.similarity(burger)\n",
    "food_burger = food.similarity(burger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200c9b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Food Fruit similarity: {food_fruit}\")\n",
    "print(f\"Fruit Burger similarity: {fruit_burger}\")\n",
    "print(f\"Food Burger similarity: {food_burger}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dd053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This vector is based on taking away the man vector from king and adding woman\n",
    "new_vector = food.vector - burger.vector + fruit.vector\n",
    "new_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d2d0bf",
   "metadata": {},
   "source": [
    "A helper function for measuring cosine similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999f742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2): \n",
    "    return 1 - spatial.distance.cosine(vec1, vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16a7be2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# run the below to have words in spacy cache for vocab\n",
    "random_words = nlp('house good pizza cars fun chess vegetable fries of apple juice kingdom burger prince house wicked this banana home island car truck dog rice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3721865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a group of words see which word is closest\n",
    "\n",
    "similarities = []\n",
    "for word in random_words:\n",
    "    if word.has_vector and word.is_alpha and word.is_lower:\n",
    "        similarities.append((cosine_similarity(new_vector,word.vector),word.text, word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dbb63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(similarities, reverse=True)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4257ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as we can observe that for a vector like king-man+woman we obviously expect a queen and it \n",
    "# proves to be successful in getting that\n",
    "\n",
    "for similarity,word,_ in  sorted(similarities,reverse=True)[:20]:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323bcbf0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "###  <span style=\"color:red\"> Exercise 2 </span>\n",
    "Repeat the above by adding vectors of 4 words of your choice.  Hint the following gives you the full vocab of words list(nlp.vocab.strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f0ea59",
   "metadata": {},
   "source": [
    "If we stack word embedding vectors on top of one another we can display them as an image. This way we can see which axes in the vector representations which are actually similar.\n",
    "\n",
    "This is just an interesting thing to do really... we don't really know what these axes represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb3eb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = []\n",
    "for similarity, word, embedding in  sorted(similarities,reverse=True)[:20]:\n",
    "    grid.append(embedding.vector)\n",
    "grid = np.array(grid)\n",
    "print(grid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9b85e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "ax.imshow(grid, interpolation='nearest', cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0f6007",
   "metadata": {},
   "source": [
    "## Loading Text\n",
    "\n",
    "We're going to load _Dracula_ which can be downloaded from Project Gutenberg [here](http://www.gutenberg.org/cache/epub/345/pg345.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa412374",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(open(\"pg345.txt\", encoding=\"utf-8\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06557812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all of the words in the text file\n",
    "tokens = list(set([w.text for w in doc if w.is_alpha and w.has_vector]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fdb64d",
   "metadata": {},
   "source": [
    "A helper function to get the word vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87648e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec(s):\n",
    "    return nlp(s).vector "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96e7312",
   "metadata": {},
   "source": [
    "Make sure things work (this should be true below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41ccc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line checks if the word \"dog\" is more similar to \"puppy\" than \"trousers\" to \"octopus\"\n",
    "cosine_similarity(vec('dog'), vec('puppy')) > cosine_similarity(vec('trousers'), vec('octopus'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bde0bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_closest(token_list, vec_to_check, n=10):\n",
    "    return sorted(\n",
    "        token_list,\n",
    "        key=lambda x: cosine_similarity(vec_to_check, vec(x)),\n",
    "        reverse=True\n",
    "    )[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4820b54e",
   "metadata": {},
   "source": [
    "This will find the 10 closest words to \"blood\" in Dracula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfececa",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_closest(tokens, vec(\"blood\"), 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe17cf5",
   "metadata": {},
   "source": [
    "###  <span style=\"color:red\"> Exercise 3 </span>\n",
    "Try to do the same thing with a different text. Can you think of word + text pairs that will have a lot of similar words or not many? E.g. a collection of medieval poetry may not have many words similar to \"computer\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
